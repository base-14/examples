# AI Content Quality Agent - Environment Variables
# Copy this file to .env and fill in your values

# =============================================================================
# LLM CONFIGURATION
# =============================================================================

# Provider: "openai" | "google" | "anthropic"
LLM_PROVIDER=openai
LLM_MODEL=gpt-4.1-nano
LLM_TEMPERATURE=0.3

# Provider API keys (only the active provider's key is required)
OPENAI_API_KEY=your-openai-api-key

# Google Gemini:
# LLM_PROVIDER=google
# LLM_MODEL=gemini-3.0-flash-preview
# GOOGLE_API_KEY=your-google-api-key

# Anthropic:
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-haiku-3-5-20241022
# ANTHROPIC_API_KEY=your-anthropic-api-key

# =============================================================================
# OPENTELEMETRY / BASE14 SCOUT
# =============================================================================

# Service identification
OTEL_SERVICE_NAME=ai-content-quality
SCOUT_ENVIRONMENT=development

# Local OTel Collector endpoint (for docker compose setup)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318

# Enable/disable telemetry (set to "true" to disable)
OTEL_SDK_DISABLED=false

# Base14 Scout credentials (for OTel Collector â†’ Scout export)
# Get these from https://app.base14.io/settings/api-keys
SCOUT_CLIENT_ID=your-scout-client-id
SCOUT_CLIENT_SECRET=your-scout-client-secret
SCOUT_TOKEN_URL=https://auth.base14.io/oauth/token
SCOUT_ENDPOINT=https://collector.base14.io

# =============================================================================
# APPLICATION
# =============================================================================

# Prompt version configuration
REVIEW_PROMPT_VERSION=v1
IMPROVE_PROMPT_VERSION=v1
SCORE_PROMPT_VERSION=v1

HOST=0.0.0.0
PORT=8000
