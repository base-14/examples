# AI Sales Intelligence - Environment Variables
# Copy this file to .env and fill in your values

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================

# Primary LLM provider: "google" | "anthropic" | "openai" | "ollama"
LLM_PROVIDER=google

# Capable model — used for complex tasks (enrich, draft)
LLM_MODEL_CAPABLE=gemini-2.5-pro

# Fast model — used for lighter tasks (score, evaluate)
LLM_MODEL_FAST=gemini-2.5-flash

# Fallback provider (used when primary fails after retries)
FALLBACK_PROVIDER=anthropic
FALLBACK_MODEL=claude-haiku-4-5-20251001

# API Keys (only the provider(s) you're using need to be set)
GOOGLE_API_KEY=your-google-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key

# LLM generation settings
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=1024

# =============================================================================
# OLLAMA (local models — no API key required)
# =============================================================================
# Run Ollama locally: https://ollama.ai
# Start the ollama compose profile: docker compose --profile ollama up

# LLM_PROVIDER=ollama
# LLM_MODEL_CAPABLE=qwen3:8b
# LLM_MODEL_FAST=qwen3:4b
# FALLBACK_PROVIDER=ollama
# FALLBACK_MODEL=qwen3:4b
# OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# DATABASE
# =============================================================================

DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5433/sales_intelligence

# =============================================================================
# OPENTELEMETRY / BASE14 SCOUT
# =============================================================================

# Service identification
OTEL_SERVICE_NAME=ai-sales-intelligence
SCOUT_ENVIRONMENT=development

# Local OTel Collector endpoint (for docker compose setup)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318

# Enable/disable telemetry (set to "false" to disable)
OTEL_ENABLED=true

# Base14 Scout credentials (for OTel Collector → Scout export)
# Get these from https://app.base14.io/settings/api-keys
SCOUT_CLIENT_ID=your-scout-client-id
SCOUT_CLIENT_SECRET=your-scout-client-secret
SCOUT_TOKEN_URL=https://auth.base14.io/oauth/token
SCOUT_ENDPOINT=https://collector.base14.io

# =============================================================================
# APPLICATION
# =============================================================================

APP_NAME=ai-sales-intelligence
LOG_LEVEL=INFO
DEBUG=false
